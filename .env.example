# Voice Memory Environment Variables
# Copy this file to .env.local and fill in your values

# =============================================================================
# REQUIRED: Supabase Configuration
# =============================================================================
NEXT_PUBLIC_SUPABASE_URL=your_supabase_project_url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key
SUPABASE_SERVICE_KEY=your_supabase_service_role_key

# =============================================================================
# REQUIRED: OpenAI Configuration
# =============================================================================
OPENAI_API_KEY=your_openai_api_key

# =============================================================================
# OPTIONAL: OpenAI Model Configuration (defaults provided)
# =============================================================================
OPENAI_WHISPER_MODEL=whisper-1
OPENAI_GPT_MODEL=gpt-4-turbo-preview

# =============================================================================
# OPTIONAL: OpenAI Rate Limiting Configuration (defaults provided)
# =============================================================================
OPENAI_WHISPER_RATE_LIMIT=50
OPENAI_WHISPER_MAX_CONCURRENT=5
OPENAI_GPT_RATE_LIMIT=200
OPENAI_GPT_MAX_CONCURRENT=10

# =============================================================================
# OPTIONAL: OpenAI Retry Configuration (defaults provided)
# =============================================================================
OPENAI_RETRY_ATTEMPTS=3
OPENAI_RETRY_BASE_DELAY=1000
OPENAI_RETRY_MAX_DELAY=10000

# =============================================================================
# OPTIONAL: Rate Limiting Configuration
# =============================================================================
USE_DATABASE_RATE_LIMITING=false

# =============================================================================
# REQUIRED: Cron Job Configuration (for automated processing)
# =============================================================================
CRON_SECRET=your_cron_secret_key_here

# =============================================================================
# OPTIONAL: Batch Processing Configuration (defaults provided)
# =============================================================================
BATCH_SIZE=5
PROCESSING_TIMEOUT_MINUTES=15

# =============================================================================
# OPTIONAL: Processing Configuration
# =============================================================================
NEXT_PUBLIC_MAX_FILE_SIZE=25000000
NEXT_PUBLIC_ALLOWED_AUDIO_TYPES=audio/mpeg,audio/mp4,audio/wav,audio/aac,audio/ogg,audio/webm

# =============================================================================
# OPTIONAL: Development Configuration
# =============================================================================
NODE_ENV=development
NEXT_PUBLIC_APP_URL=http://localhost:3000

# =============================================================================
# OPTIONAL: CORS Configuration
# =============================================================================
# CORS_ORIGINS=https://your-production-domain.com,https://your-other-domain.com
# 
# Development: Defaults to http://localhost:3000
# Production: Must be HTTPS origins only (no localhost, wildcards, or HTTP)
# 
# Examples:
# - Single domain: CORS_ORIGINS=https://myapp.vercel.app
# - Multiple domains: CORS_ORIGINS=https://myapp.com,https://api.myapp.com
# - Vercel deployment: Automatically uses https://${VERCEL_URL} if not specified

# =============================================================================
# OPTIONAL: Authentication Token (for scripts and automation)
# =============================================================================
VOICE_MEMORY_AUTH_TOKEN=your_auth_token_here

# =============================================================================
# OPTIONAL: Base URL Configuration (automatically detected in most cases)
# =============================================================================
# NEXT_PUBLIC_VERCEL_URL=your_vercel_deployment_url  # Set by Vercel automatically
# VERCEL_URL=your_vercel_deployment_url              # Set by Vercel automatically  
# NEXT_PUBLIC_BASE_URL=https://your-custom-domain.com  # Override for custom domains
VERCEL_ENV=production

# =============================================================================
# PRODUCTION DEPLOYMENT NOTES
# =============================================================================
# 
# For production deployment on Vercel:
# 1. Set all REQUIRED variables in your Vercel project settings
# 2. Ensure CRON_SECRET is a strong, unique value (32+ characters recommended)
# 3. Set NODE_ENV=production
# 4. Configure CORS_ORIGINS for your production domains (HTTPS only)
# 5. Configure Vercel cron jobs to use your CRON_SECRET
# 6. Set appropriate rate limits based on your OpenAI plan
# 7. Consider enabling USE_DATABASE_RATE_LIMITING for better rate limit tracking
# 8. Adjust PROCESSING_TIMEOUT_MINUTES based on your function timeout limits
# 9. Base URL is automatically detected from NEXT_PUBLIC_VERCEL_URL or VERCEL_URL
#    - Override with NEXT_PUBLIC_BASE_URL only if using custom domain
#
# Recommended production values:
# - BATCH_SIZE: 3-5 (depending on your processing capacity)
# - PROCESSING_TIMEOUT_MINUTES: 14 (for 15-minute Vercel function timeout)
# - OPENAI_WHISPER_RATE_LIMIT: 50 (or your plan's limit)
# - OPENAI_GPT_RATE_LIMIT: 200 (or your plan's limit)
# - USE_DATABASE_RATE_LIMITING: true
# - OPENAI_WHISPER_MODEL: whisper-1 (latest stable)
# - OPENAI_GPT_MODEL: gpt-4-turbo-preview (or your preferred model)
#
# Processing Configuration:
# - PROCESSING_TIMEOUT_MINUTES: Maximum time for a single note to process
#   * Should be less than your function timeout (e.g., 14 for 15-min limit)
#   * Helps prevent stuck processing and resource leaks
#   * Used by both individual processing and batch processing
# - BATCH_SIZE: Number of notes to process in a single batch
#   * Lower values = more frequent processing, less chance of timeouts
#   * Higher values = more efficient, but higher timeout risk
#   * Recommended: 3-5 for production, 1-2 for testing
#
# Rate Limiting Notes:
# - OPENAI_WHISPER_RATE_LIMIT: Requests per minute for Whisper API
# - OPENAI_GPT_RATE_LIMIT: Requests per minute for GPT API
# - OPENAI_WHISPER_MAX_CONCURRENT: Maximum concurrent Whisper requests
# - OPENAI_GPT_MAX_CONCURRENT: Maximum concurrent GPT requests
# - USE_DATABASE_RATE_LIMITING: Enable database-backed rate limiting for better tracking
#
# Retry Configuration:
# - OPENAI_RETRY_ATTEMPTS: Number of retry attempts for failed API calls
# - OPENAI_RETRY_BASE_DELAY: Base delay in milliseconds between retries
# - OPENAI_RETRY_MAX_DELAY: Maximum delay in milliseconds between retries
#
# Error Handling and Monitoring:
# - The system includes comprehensive error tracking and processing locks
# - Failed notes are automatically retried with exponential backoff
# - Processing metrics are collected for monitoring and optimization
# - Circuit breaker pattern protects against cascading OpenAI API failures
# - Health checks are available at /api/cron/process-batch (GET) 